steps:
  # ============================================
  # PYSPARK SCRIPTS UPLOAD TO GCS
  # ============================================
  
  # Upload PySpark scripts to GCS for Dataproc Serverless
  - name: 'gcr.io/cloud-builders/gsutil'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        echo "Uploading PySpark scripts to GCS..."
        
        # Create scripts directory structure in GCS
        gsutil -m cp -r data_processing/calculate_pool_metrics_spark.py \
          gs://${PROJECT_ID}-dataproc/scripts/
        
        gsutil -m cp -r forecasting/forecast_pools_spark.py \
          gs://${PROJECT_ID}-dataproc/scripts/
        
        gsutil -m cp -r database/db_utils_spark.py \
          gs://${PROJECT_ID}-dataproc/scripts/database/
        
        gsutil -m cp -r database/db_utils.py \
          gs://${PROJECT_ID}-dataproc/scripts/database/
        
        gsutil -m cp -r database/__init__.py \
          gs://${PROJECT_ID}-dataproc/scripts/database/
        
        gsutil -m cp -r config.py \
          gs://${PROJECT_ID}-dataproc/scripts/
        
        echo "PySpark scripts uploaded successfully"

  # ============================================
  # DOCKER IMAGE BUILDS
  # ============================================

  # Build Web Scraping Image
  - name: 'gcr.io/cloud-builders/docker'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        # Try to pull the latest web-scraping image for caching
        docker pull gcr.io/$PROJECT_ID/defi-pipeline-web-scraping:latest || true
        
        # Build the web-scraping image
        docker build \
          -f dockerfiles/Dockerfile.web-scraping \
          -t gcr.io/$PROJECT_ID/defi-pipeline-web-scraping:latest \
          -t gcr.io/$PROJECT_ID/defi-pipeline-web-scraping:$COMMIT_SHA \
          --cache-from gcr.io/$PROJECT_ID/defi-pipeline-web-scraping:latest \
          .

  # Build ML/Science Image (still needed for optimize_allocations and non-Spark jobs)
  - name: 'gcr.io/cloud-builders/docker'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        # Try to pull the latest ml-science image for caching
        docker pull gcr.io/$PROJECT_ID/defi-pipeline-ml-science:latest || true
        
        # Build the ml-science image
        docker build \
          -f dockerfiles/Dockerfile.ml-science \
          -t gcr.io/$PROJECT_ID/defi-pipeline-ml-science:latest \
          -t gcr.io/$PROJECT_ID/defi-pipeline-ml-science:$COMMIT_SHA \
          --cache-from gcr.io/$PROJECT_ID/defi-pipeline-ml-science:latest \
          .

  # Build Lightweight Image
  - name: 'gcr.io/cloud-builders/docker'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        # Try to pull the latest lightweight image for caching
        docker pull gcr.io/$PROJECT_ID/defi-pipeline-lightweight:latest || true
        
        # Build the lightweight image
        docker build \
          -f dockerfiles/Dockerfile.lightweight \
          -t gcr.io/$PROJECT_ID/defi-pipeline-lightweight:latest \
          -t gcr.io/$PROJECT_ID/defi-pipeline-lightweight:$COMMIT_SHA \
          --cache-from gcr.io/$PROJECT_ID/defi-pipeline-lightweight:latest \
          .

  # Build Database Image
  - name: 'gcr.io/cloud-builders/docker'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        # Try to pull the latest database image for caching
        docker pull gcr.io/$PROJECT_ID/defi-pipeline-database:latest || true
        
        # Build the database image
        docker build \
          -f dockerfiles/Dockerfile.database \
          -t gcr.io/$PROJECT_ID/defi-pipeline-database:latest \
          -t gcr.io/$PROJECT_ID/defi-pipeline-database:$COMMIT_SHA \
          --cache-from gcr.io/$PROJECT_ID/defi-pipeline-database:latest \
          .

  # ============================================
  # PUSH IMAGES
  # ============================================

  # Push Web Scraping Image
  - name: 'gcr.io/cloud-builders/docker'
    args: ['push', 'gcr.io/$PROJECT_ID/defi-pipeline-web-scraping:latest']

  - name: 'gcr.io/cloud-builders/docker'
    args: ['push', 'gcr.io/$PROJECT_ID/defi-pipeline-web-scraping:$COMMIT_SHA']

  # Push ML/Science Image
  - name: 'gcr.io/cloud-builders/docker'
    args: ['push', 'gcr.io/$PROJECT_ID/defi-pipeline-ml-science:latest']

  - name: 'gcr.io/cloud-builders/docker'
    args: ['push', 'gcr.io/$PROJECT_ID/defi-pipeline-ml-science:$COMMIT_SHA']

  # Push Lightweight Image
  - name: 'gcr.io/cloud-builders/docker'
    args: ['push', 'gcr.io/$PROJECT_ID/defi-pipeline-lightweight:latest']

  - name: 'gcr.io/cloud-builders/docker'
    args: ['push', 'gcr.io/$PROJECT_ID/defi-pipeline-lightweight:$COMMIT_SHA']

  # Push Database Image
  - name: 'gcr.io/cloud-builders/docker'
    args: ['push', 'gcr.io/$PROJECT_ID/defi-pipeline-database:latest']

  - name: 'gcr.io/cloud-builders/docker'
    args: ['push', 'gcr.io/$PROJECT_ID/defi-pipeline-database:$COMMIT_SHA']

  # ============================================
  # COMPLETION LOG
  # ============================================
  
  - name: 'gcr.io/cloud-builders/gcloud'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        echo "Build and push complete:"
        echo ""
        echo "ðŸ“¦ Docker Images:"
        echo "  - Web Scraping: gcr.io/$PROJECT_ID/defi-pipeline-web-scraping:$COMMIT_SHA"
        echo "  - ML/Science: gcr.io/$PROJECT_ID/defi-pipeline-ml-science:$COMMIT_SHA"
        echo "  - Lightweight: gcr.io/$PROJECT_ID/defi-pipeline-lightweight:$COMMIT_SHA"
        echo "  - Database: gcr.io/$PROJECT_ID/defi-pipeline-database:$COMMIT_SHA"
        echo ""
        echo "âš¡ Spark Scripts (GCS):"
        echo "  - gs://${PROJECT_ID}-dataproc/scripts/calculate_pool_metrics_spark.py"
        echo "  - gs://${PROJECT_ID}-dataproc/scripts/forecast_pools_spark.py"
        echo ""
        echo "Cloud Run Jobs using specialized images will pick up new images on next execution."
        echo "Dataproc Serverless jobs will use latest scripts on next execution."

images:
  - 'gcr.io/$PROJECT_ID/defi-pipeline-web-scraping:latest'
  - 'gcr.io/$PROJECT_ID/defi-pipeline-web-scraping:$COMMIT_SHA'
  - 'gcr.io/$PROJECT_ID/defi-pipeline-ml-science:latest'
  - 'gcr.io/$PROJECT_ID/defi-pipeline-ml-science:$COMMIT_SHA'
  - 'gcr.io/$PROJECT_ID/defi-pipeline-lightweight:latest'
  - 'gcr.io/$PROJECT_ID/defi-pipeline-lightweight:$COMMIT_SHA'
  - 'gcr.io/$PROJECT_ID/defi-pipeline-database:latest'
  - 'gcr.io/$PROJECT_ID/defi-pipeline-database:$COMMIT_SHA'

options:
  machineType: 'E2_HIGHCPU_8'
  logging: CLOUD_LOGGING_ONLY
